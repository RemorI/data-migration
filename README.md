# Data migration
Es importante entender que los beneficios que vienen con el uso del almacenamiento en la nube son la viabilidad, latencia, la auto orquestación, manejar coneccionse complicadas y escalar el tamaño, además de muchas cosas más pero estos suelen ser los principales problemas con los que hay que lidiar con un storage on-premise. 
Primeramente tenemos la relocalización de aplicaciones a una máquina virtual dentro de la nube, a través de lift-and-shift.
Pero generalmente hay más complejos teniendo que realizar re-estructuraciones en la arquitectura de las data stores.<br>
Cuando se realiza una migraciones de datos no hay que perder de vista la **seguridad**, **cumplimiento**, **disponibilidad** e **integridad**. Requiere un esfuerzo coordinado entre bases de datos, desarrollo de aplicaciones, data, DevOps y equipo de infraestructura.

## Lift and shift
*Lift-and-shift*, es una estrategia de migración de aplicaciones que primeramente los lleva offline antes de llevarlo a la nube, y una vez subido este método puede hacer uso de una estructura tipo servicio (IaaS), plataforma como servicio (Paas) o software como servicio (SaaS).
- Tiene el beneficio de ser efectivo en costos para las migraciones de aplicaciones a la nube.
- Permite a las compañías implementar el guardado en nube sin afectar a la data on-premise.
- Pero hay que tener cuidado con este método ya que se debería elegir una nube que permita una simple integración y migración sin tantas complicaciones.

*Proceso*: Es una alternativa a una migración completa y es bastante efectivo como concepto. 
1. Primeramente se debe hacer una preparación de los datos on-premise y del environment en la nube.
2. El proceso de migración se debe hacer el pasos sin sincronicidad porque puede generar problemas de conflicto en las aplicaciones on-premise. Seleccionar solamente ciertos trozos de dato para moverlos de una forma más rápida y eficiente para llevarlos a la nube.
3. Y una vez que esa migración se hizo se puede mover los demás trozos de data con normalidad, pero de todas formas debe ser suave y lento.

*Consideraciones para su utilización*: Hay una diferencia considerable entre shifting data y transfering data, los datos pueden ser shifted de tu sistema a la nube pero va a necesitar reengineering antes de poder ser usada.<br>
Los datos puede ser procesados y movidos por diferentes localizaciones antes de llegar al destino, y es sumamente necesario saber dónde está guardada y que se está guardando esa información luego de cada proceso.<br>
También es necesario saber que los datos puede ser vulnerables en todo el transito y procesamiento, así que hay que asegurar las medidas de seguridad previamente.

## More complex Data Migration
Al tener que trabajar con migraciones de datos más complejas, empezamos a tener que realizar muchas más correcciones en el sistema para que todo pueda seguir funcionando con normalidad. Primero para asegurar que esté integrado de la misma forma que en la version anterior y que todo funciona de forma perfecta, hay que asegurar principales mantenimientos y cuidados a tener en cuenta para que los datos no se vean perjudicados.
1. Seguridad y cumplimiento, los datos se tienen que mantener seguros y mantener un cumplimiento regulatorio y con políticas internas en cada estapa de la migración.
2. Disponibilidad del sistema, es muy relevante saber el tiempo en el que va a estar dado de baja el sistema por temas de la migración y cómo va a ser el nuevo horario. Pero generalmente por el tipo de migración suele no haber interrupción en la disponibilidad ya que se mantiene la base mientras se prepara la migración en otro sitio diferente. También el nuevo sistema se puede probar en solo una pequeña población para que funcionen como testers del funcionamiento de la nueva bbdd. Aún así se debe asegurar **mínimo** tiempo de caída.
3. Data loss, es muy importante evitar la pérdida de datos durante el período de migración, puede suceder que se escriba es un lugar y otro no o que simplemente no se esté escribiendo en ninguno.
4. Compatibilidad, para el correcto funcionamiento del sistema se debe asegurar que se mantenga la misma compatibilidad e integración con el sistema anterior a ser migrado. Eso se refiere tanto a la conectividad con aplicaciones, otras bases de datos e incluso integraciones específicas con otras pipelines
5. Sobrecoste, es importante elegir la nueva bbdd o almacenamiento teniendo en cuentas las previas necesidades de la bbdd anterior porque sino podemos pasar problemas de costos por el mantenimiento de una bbdd demasiado grande o demasiado pequeña para realmente lo necesario, además de tener en cuenta los costos de ampliación y escalado. Además de que la transferencia de datos también tienen un costo, no solo el mantenimiento de la bbdd.

Por eso los principales problemas con los que hay que lidiar son, el riesgo de pérdida de datos, los tiempos de caída y que los datos tengan integridad y precisión. <br>
Es esencial que en cualquier transferencia de datos se pueda mantener cuidado lo siguiente:
1. Data backup
2. Data profiling and analysis
3. Data migration assessment
4. Cleansing data
5. Migration tools

Al hacer un análisis más profundo en estos temas, se puede hablar de las mejores y más básicas prácticas que jamás pueden faltar sin importar qué en la migración de datos, ya sea on-premise to cloud o cloud to cloud.
1. Antes de empezar a pensar en la migración de los datos, es importante conocer los metadatos de la bbdd, además de conocer los propósitos para la que está armada ya que esto va a hablar muchísimo de su estructura y cómo se tiende a utilizar para poder conseguir la mejor eficiencia.
    - Asegurar la calidad de los datos, es muy necesario para que a la hora de realizar la migración, no se envíen datos con errores, incompletos o directamente equivocados a la nueba bbdd
    - Entender la complejidad de los datos, el análisis de la base de datos es fundamental para poder una mejor planeación y preparación a la hora de la migración, ya que esto permite conocer más a fondo cómo es el comportamiento que se debe replicar y no solo la forma
    - Mitigación de riesgos, al conocer la fuente de los datos se pueden evitar riesgos más allá de los datos dentro de la fuente, sino también del exterior, las dependencias e independencias de los datos que van a tener que volver a ser conectadas o asegurarse de que no estén conectadas.
2. Data backup, para asegurar la integridad de los datos es necesario que siempre haya un backup de los datos y sobre todo antes de cada cambio en caso de cometer errores. Esto genera mayor seguridad al trabajar con estos datos porque nunca se va a perder la integridad de los mismos, en caso de que los datos transferidos se hayan corrompido o no se movieran de la forma esperada aún así se mantiene un backup con los datos fuente, además de la integridad también evitamos un principal problema que es la pérdida de datos.
    - Asegurar la integridad de los datos, mantiene los datos íntegros y seguros luego de la migración para salvaguardar de pérdidas o corrupción
    - Mitigador de riesgos, se evitan muchos riesgos al tener backup ya que siempre se puede volver un paso atrás asegurado
    - Continuidad del negocio, esto también ayuda la negocio porque estos datos van a quedar guardados en el sistema y van a poder ser consultados cuando sea necesario
3. Evaluación de la migración de datos, hay que hacer un buen y práctico planteamiento de cómo va a ser la mejor forma de migrar estos datos conociendo la metadata de la bbdd fuente, a dónde se enviarán, qué dependencias tiene y cuáles necesita, qué tipo de trabajo o aplicación la utilizará y cómo. Son muchas cosas a tener en cuenta que permiten elegir la mejor opción a la otra de la migración, además al conocer esta información también podemos evitar futuros problemas, evitar mucho tiempo de caída y poder llevar a cabo este plan con mayor rapidez al conocer la mayoría de contratiempos.
    - Identificador de riesgos, ayuda a conocer potenciales riesgos y complicaciones a la hora de migrar los datos, permitiendo que la organización mitigue de forma temprana estos errores
    - Estimación de costos, al conocer la metadata de la bbdd y cuál va a ser la nueva bbdd donde se va a almacenar, se puede realizar estimaciones en costos para un correcto previo análisis de las opciones a considerar
    - Mapeado de dependencias, al tener conocimiento de las dependencias estas pueden ser preparadas con anterioridad para que al momento de realizar la migración, toda la información se mantenga actualizada o funcionando como se espera al conocer cuáles son sus dependencias
4. Perfilación y análisis de datos, para asegurar la integridad y precisión se requiere un previo análisis que permita entender el formato, estructura y la calidad que tienen los datos antes de la migración. Para poder tener una base de datos limpia y de calidad antes de realizar la migración, a partir de esto están las dos estrategias de migración de datos más conocidas que son el **Big bang** y el **Trickle**. El "Big bang" se utiliza sobre todo al saber que hay una ventana de tiempo de inactividad, el "Trickle" cuando el sistema se tiene que mantener lo más posiblemente ininterrumpido.
    - Asegurar la calidad, al realizar una perfilación de los datos se puede realizar una transformación con antelación para mantener los datos con la mayor limpieza y calidad posible
    - Mejora en la eficiencia, se nota una mejora considerable en la eficiencia una vez es eliminada la información duplicada, obsolea y reduciendo así el tiempo y esfuerzo en la migración
    - Mejora en el mapeado, el análisis permite una mejora en la precisión del mapeado asegurando datos más limpios que tengan más valor para una transferencia más rápida y que la compatibilidad de todas las dependencias sea sin problemas
5. Limpieza de los datos, la migración de los datos generalmete primero pasa por un proceso llamado **GIGO** (garbage in, garbage out), en el caso que no se realicen los anteriores procesos asegurando una calidad mínima de los datos, se van a gastar recursos en mover datos inútiles, incorrectos e incompletos de un lugara a otro. Por eso es muy necesario realizar un "deep clean" eliminando discrepancias, datos viejos, inútiles y duplicados lo que rápidamente aumentará la calidad de los datos. Además es muy importante ir realizando testeos y validaciones a lo largo de la migración para seguir asegurando dicha calidad y que los datos no presenten errores, corrupción o desgloses no deseados.
    - Mejora en la calidad de los datos, al realizar limpiezas se obtiene una base de datos más liviana y actualizada que permite tener los datos mejor
    - Mejora en la toma de decisiones, los datos de calidad permite que se tomen decisiones con mayor información y conocimiento del estado actual de la base de datos fuente
    - Optimización en el rendimiento del sistema, una buena limpieza disminuye el volumen y la complejidad, sobre todo de datos inútiles que hacen el proceso más complicados al no ir de acuerdo a como está la estructura hecha para dicha bbdd.
6. Herramientas de migración, algunas herramientas básicas pueden ser para el uso de ETL que permite extraer la información desde varias funciones, realizar las transformaciones necesarias que primero aseguren una calidad mínima, luego cambios necesarios para el funcionamiento adecuado en la nueva bbdd y por último para ya sea actualizaciones o mejoras en las dependencias, también hay que tener en cuenta el canal de DevOps para realizar el testeado el despliegue y el monitoreo de los procesos.
    - Aumento en la eficiencia, las herramientas de migración automatizan el proceso de transferencia de datos, reduciendo el tiempo y evitando errores manuales, y por eso mejorando la eficiencia base.
    - Manejo de las complejidades, estas herramientas realizan actividades más complicadas como la conversión de esquemas y la transformación de los datos, simplificando las migraciones complejas
    - Validación de los datos, a veces estas herramientas tienen funciones para la validación de datos, asegurando integridad y precisión en el proceso de migración.
7. Test de migración, el testeo y la validación sirven como puntos finales para asegurar la precisión y dependencias en la hora de realizar una transferencia de datos de un fuente a un destino diferente. Y estos son importantes ya que son los primeros en revisar errores, corrupción o pérdidas de datos por la transferencia. Es bueno crear un sistema de testeo separado que se parezca al de producción solamente para observar cómo se manejaría en un sistema lo más real y así observar mejor los problemas que generalmente aparecen en la producción y no en un sistema especialmente creado para el testeo que suele estar limpio para evitar que se mezclen con otros errores.
    - Validación de procesos, asegura la compatibilidad, integridad de los datos y la funcionabilidad del sistema en un ambiente señalado
    - Optimización en el rendimiento, permite una observación más específica en el rendimiento lo que permite conocer cómo mejorar el rendimiento base y donde ocurren las demoras
    - Asegurar la continuidad del negocio, al realizar simulaciones de migración en escenarios realistas (no solo en lugares controlados para testing) se puede intentar evitar los retrasos, caídas y mantener el sistema funcionando porque ya se conocen las "debilidades"
8. Mapeado de datos, permite conocer con mayor facilidad la diferencia entre la fuente de los datos y la estructura de datos a la que se quiere llegar al realizar la migración, ayuda a la hora de querer modificar el formato de los datos, el tipo y aún así realizar una correcta verificación de la integridad y la comprensividad de los datos. Realizar un mapeado de los datos a lo largo de la migración de los datos permite que dicha migración sea lo más suave y con los resultados más esperables hacia lo correcto, además de que se mantengan las observaciones realizadas a lo largo del proceso.
    - Entender la estructura de los datos, permite una migración más precisa y una mantenimiento en la relación entre los datos que vaya a lo largo del formato y estructura deseado al que se quiere llegar al terminar el proceso de migración
    - Transformación eficiente de los datos, permite una eficiente transformación de los datos entre los diferentes formatos y esquemas así permitiendo un correcto stream de migración reduciendo las complejidades
    - Minimizar la pérdida de datos, al mapear los bloques de datos y sus funciónes, las organizaciones pueden minimizar el riesgo de perder datos o un breakdown durante la migración, asegurando la integridad de os datos.
9. Seguridad y cumplimiento, cuando la transferencia de datos requiere cierto nivel de privacidad y cuidado es ideal que se realice un correcto manejo de los datos sensibles asegurando la seguridad que permita la integridad, la confidencialidad y la adherencia de las regulaciones pertinentes. **Encriptación** asegura la seguridad de los datos al hacerlos inaccesibles sin una key especial dependiendo del nivel de seguridad que se requiera. **Data masking** mantiene la confidencialidad de los detalles con chequeos regulares en la precisión y compromiso con las regulaciones.
    - Clasificación de los datos, organizar los datos basados en las regulaciones y seguridades necesarias evitará problemas futuros con la FALTA de seguridad
    - Asegurador de riesgos, determinar las potenciales backdoors y errores, además de pérdida de seguridad previo a que ocurran para mantener la seguridad óptima y necesaria dependiendo de la necesidad de los datos
    - Mapeado de datos, crear un mapeado de la sensibilidad de los datos para saber las medidas de seguridad y las regulaciones que cada uno tendrá que cumplir a lo largo de la transferencia y sobre todo una vez en la nueva bbdd.
10. Actividades post-migración, 